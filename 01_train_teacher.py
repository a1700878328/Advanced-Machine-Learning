import os
import json
import pandas as pd
import torch
import ast
import random
from torch.utils.data import Dataset
from transformers import Qwen2VLForConditionalGeneration, Qwen2VLProcessor, Trainer, TrainingArguments, \
    DataCollatorForSeq2Seq
from peft import LoraConfig, get_peft_model, TaskType
from qwen_vl_utils import process_vision_info

# --- é…ç½® ---
MODEL_ID = "Qwen/Qwen2-VL-2B-Instruct"  # 2Bæ¨¡å‹ï¼Œå®Œå…¨åˆè§„ï¼Œæ— éœ€é‡åŒ–
DATA_DIR = "custom_dataset"
TRAIN_CSV = os.path.join(DATA_DIR, "train_labels.csv")
IMG_DIR = os.path.join(DATA_DIR, "train")
OUTPUT_DIR = "teacher_checkpoint"


# --- æ•°æ®é›†ç±» ---
class VQADataset(Dataset):
    def __init__(self, csv_file, img_dir, processor):
        self.df = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.processor = processor

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]

        # 1. å¤„ç†è§£é‡Š (éšæœºé€‰ä¸€ä¸ª)
        explanation = ""
        try:
            if isinstance(row['explanation'], str) and row['explanation'].startswith('['):
                expl_list = ast.literal_eval(row['explanation'])
                explanation = random.choice(expl_list)
            else:
                explanation = str(row['explanation'])
        except:
            explanation = "No explanation."

        # 2. æ„å»ºå¯¹è¯
        # æˆ‘ä»¬è®­ç»ƒæ¨¡å‹æŒ‰ç…§å›ºå®šæ ¼å¼è¾“å‡º
        answer_text = f"Answer: {row['answer']}\nExplanation: {explanation}"

        image_path = os.path.join(self.img_dir, row['file'])

        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image_path},
                    {"type": "text", "text": row['question']}
                ]
            },
            {
                "role": "assistant",
                "content": [{"type": "text", "text": answer_text}]
            }
        ]

        # 3. é¢„å¤„ç†
        text = self.processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)
        image_inputs, video_inputs = process_vision_info(messages)

        inputs = self.processor(
            text=[text],
            images=image_inputs,
            videos=video_inputs,
            padding="max_length",
            truncation=True,
            max_length=512,  # æ§åˆ¶é•¿åº¦çœæ˜¾å­˜
            return_tensors="pt",
        )

        # ç§»é™¤batchç»´åº¦
        inputs = {k: v.squeeze(0) for k, v in inputs.items()}

        # è®¾ç½® Labels (å¿½ç•¥ padding)
        inputs["labels"] = inputs["input_ids"].clone()
        inputs["labels"][inputs["labels"] == self.processor.tokenizer.pad_token_id] = -100

        return inputs


def train_teacher():
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ Teacher è®­ç»ƒ...")

    # 1. åŠ è½½æ¨¡å‹ (BF16, 16GBæ˜¾å­˜æ¯«æ— å‹åŠ›)
    model = Qwen2VLForConditionalGeneration.from_pretrained(
        MODEL_ID, torch_dtype=torch.bfloat16, device_map="auto"
    )
    processor = Qwen2VLProcessor.from_pretrained(MODEL_ID, min_pixels=256 * 256, max_pixels=512 * 512)

    # 2. æ·»åŠ  LoRA (å¾®è°ƒ)
    peft_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM, r=16, lora_alpha=32, lora_dropout=0.1,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    )
    model = get_peft_model(model, peft_config)
    model.print_trainable_parameters()

    # 3. å‡†å¤‡æ•°æ®
    dataset = VQADataset(TRAIN_CSV, IMG_DIR, processor)

    # 4. è®­ç»ƒå‚æ•°
    args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        per_device_train_batch_size=4,  # 16GB å¯ä»¥å°è¯• 4 æˆ– 8
        gradient_accumulation_steps=4,  # ç­‰æ•ˆ batch size 16
        num_train_epochs=5,  # æ•™å¸ˆæ¨¡å‹ä¸ç”¨è·‘å¤ªä¹…
        learning_rate=2e-4,
        bf16=True,  # å¼€å¯ BF16 åŠ é€Ÿ
        logging_steps=10,
        save_strategy="epoch",
        dataloader_num_workers=0,
        remove_unused_columns=False,
        report_to="none"
    )

    trainer = Trainer(
        model=model, args=args, train_dataset=dataset,
        data_collator=DataCollatorForSeq2Seq(tokenizer=processor.tokenizer, padding=True),
    )

    trainer.train()
    trainer.save_model(os.path.join(OUTPUT_DIR, "final"))
    processor.save_pretrained(os.path.join(OUTPUT_DIR, "final"))
    print("âœ… Teacher æ¨¡å‹è®­ç»ƒå®Œæˆï¼")


if __name__ == "__main__":
    train_teacher()